Currently, the type system has several elements:
  - primitive types and type constructors
  - table of type abbreviations (just type constants)
  - table of user-constructed types: extension by new type symbols and relations
    (which may be recursive)
  - a table of projector and injector names assosiated to user-constructed
    (both have syntactic uses that go beyond their use as functions, but there
    is lack of symmetry in that only projectors can be aliased in these uses)

"Type" symbols (introduced by |set_type|) will be used to designate not only
types, but certain also type constructors, which are maps from $n$-tuples of
types (where $n\in\N$ is the arity of the type symbol) to types (one output).

These come in two varieties: those that are merely abbreviations (that can be
given by type-lambda expressions, maybe with a fix point combinator thrown in
for recursive types or type constructors) and those whose output type is opaque
(like primitive types). Of the first type would be one like the Haskell Maybe
type constructor (the type map T=>(void|T) and an infinite list constructor
T=>rec_type: r=(->T,r), of the second kind SearchTree: T=>(NewType); here
NewType is an opaque type determined implicitly by a bunch of related values
that are entered into the global tables where SearchTree is defined. (These
values must involve at least one constructor function returning NewType, or else
one can never create values of this type; the constructor presumably will be of
type (Order(T)->NewType) where |Order| is a type constructor of the first kind,
describing a comparison function or other elements that allow values of type |T|
to be totally ordered.)

With the introduction of types and type constructors of the second type, the
whole type system must be revised. The new types must be added to the list of
primitive types, and the new type constructors extend the structure of type
expressions. If even higher order type constructors are allowed (those taking
type constructors as one of their arguments) then the type structure must also
cater for this. Probably the latter is useful, if one needs to define type
constructors that work across a class of types (obtained from some other
constructor) but not all types; it is not an urgent need though. Examples given
for Haskell 'kind' are quite unconvincing; before ever giving an example of code
that could not be written without higher order kinds, they seem to need to talk
about Haskell-specific (maybe non-orthogonal) details such as Constraints.
Nonetheless it is conceivable that some code can be usefully parametrised over
higher kind types, so when redoing the type system it might be an idea to leave
the possibility of representing these in type values during type analysis.

It appears that the following general principles should apply:

- In each group of type (constructor) definitions, each clique of mutually
  recursive items acts like a collection of primitive types (or primitive type
  constructors all of the same arity). The remaining items are treated as
  abbreviations only, and have no implications for the set of available types.
  For simplicity and maybe for now, we treat all cliques as distinct, even if
  their definitions would be isomorphic; this mostly has the benefit that we do
  not need to worry about a recursively defined type being an instance of a
  recursively defined type constructor (different recursive definitions give
  different types). However beyond this, equivalence is purely structural.

- Every type definition, abbreviation or not, is made in the context of zero or
  more type abstractions: names are introduced that can stand for abitrary types
  and their number is the arity of the type symbol(s) defined.

- Opaque types can be introduced by formulating their intergace, probably a
  bunch of functions related to the type, some of which can build values of the
  type. All this can be inside a constext with abstracted types, so that one
  gets opaque type constructors. (This has not yet been addressed at all.)

-------------------------------------------------------------------------------

Come to think of it, there seem to be two mechanisms that could be treated
separately. The first is a mechanism to write type-lambda-expressions (possibly
with many-kinded arguments) and to introduce abbreviations for them. The second
is a (curently inexistent) mechanism to introduce new (opaque) types and type
constructors, and their "specification" using provided value types, with
implementation types given by type-lambda-expressions, and implementation values
matching the specification types.

A third related issue is to be able to define values with partically
undetermined types, like generic empty lists but also functions with second or
higher order types. In principle these are not first-class values, but objects
that become actual values by specifying the missing types, which could be done
partially by type automatic type deduction, and if needed by explicit
specialisation by the user (as currently gcd@(int,int) somewhat does, but it
would be more like #@[int] for the generic row-length operator #). This is done.

Deployment plan:

+ Extend type system such that types of expressions can be defined as dependent
  on a set of fresh (dummy) type names, and then given by a type-valid
  expression using those type names.

+ Adapt type checking algorithm to handle such generic type values, and to a
  certain extent provide automatic specialisation of them to match the type
  constraints given by the expression being analysed. The analysis may enter
  new type indeterminates into the context, remove them when specialised, and
  if some are left at the end of the anaylysis, produce a generic type as
  result. This procedure should in particular (and at the very least) handle
  the calling of higher-order functions (those with a generic type).

- Allow introducing type genericity in processing certain definitions and, why
  not, in expressions to be evaluated. Introducing can be explicit (say
  'any_type S,T') to introduce local names to the abstracted types, but it could
  also occur implicitly when invoking values with generic types.

- With all that in place, define a mechanism (syntax and semantics) to introduce
  new primitive types and constructors. (This could in fact be done _before_ all
  the genericity stuff is introduced, but then it would probably have to be
  redone afterwards. The chosen order also gives the occasion to clean up our
  act for existing generic functions before introducing type abstraction.) This
  mechanism should probably give some thought to projectors and injectors as
  well. The mechanism essentially should say: New primitive types, and type
  constructors and such, can be defined by (in the context of new dummy type
  names) introducing a new name for the primitive (maybe allow more than one?),
  and an initial (tuple) type, expressed in terms of the primitive (and of
  course any existing types) that serves as specification for it; then an
  implementation is provided that specifies a concrete type (or type lambda
  expression?) to be used to implement the primitive, and a (tuple) value to
  match to specification (with the concrete type substituted for the ne
  primitive name). Once processed, the type system is extended with the new
  primitive (much as it is currently extended when a new possibly recursive set
  of type equations is processed, except that now we extend by new primitives,
  not by new infinite types).


Structure of new (polymorphic) types and operations to be implemented for them

Besides primitive types, there will be primitive type constructors. Any
fully-applied well-formed combination of primitives is a type that will be
considered primitive, in the sense that it fails to match any specific type form
(like being a function type, or a 3-tuple type), so that only exact type match
can allow for a usage of subexpressions with such a type.